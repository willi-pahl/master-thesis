\chapter{Abstract}
In erster Linie besteht die Zielsetzung dieser Thesis darin, die Fähigkeiten der generativen KI zu prüfen und verschiedenen Modelle zu vergleichen, inwieweit sich diese für die Webanwendungsentwicklung für Unternehmen und Entwicklern aus diesem Bereich, eigenen. In dem Vergleich werden \textit{Cloused-Source-Modelle} von kommerziellen Anbietern mit \textit{Open-Source-Modellen} verglichen. Erstaunlicherweise schneiden die kommerziellen Modelle bei dem HumanEval-XL Benchmark nicht so überzeugend ab wie zuvor erwartet. Getestet werden die Programmiersprache PHP mit deutschsprachigen Proben aus dem genannten Benchmark. Trotz des angewendeten Benchmarks eigenen sich diese nur bedingt, um den vollen Umfang von LLMs zu evaluieren. Dieses Problem entsteht dar die generative KI nicht wie ein deterministisches System agiert, sondern es wird eine Wahrscheinlichkeit berechnet, welches die beste Lösung sein könnte. Somit zeigen die LLMs ein sehr dynamisches Verhalten, was mit statischen Benchmarks schwer abzudecken ist. Dennoch liefert der Benchmarks erste Ergebnisse und Modelle können verglichen werden. Nachdem die Evaluierung durchgeführt abgeschlossen ist, werden verschiedene Ansätze zur Optimierung der Eingabeaufforderung umgesetzt und ebenfalls evaluiert. Zum einen zeigt das Framework \texttt{DSPy} bei einigen Modellen eine signifikante Verbesserung der Ergebnisse, die so nicht erwartet wird. Zum Anderen gibt es Modelle, bei denen eine Verschlechterung der Ergebnisse eintritt und Modelle mit einer großen Anzahl an Parametern können aufgrund von Fehler nicht evaluiert werden.

