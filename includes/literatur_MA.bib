%----------- Start: Einleitung -------------------------------------------------------------

@online{zan-2022,
	author = {given-i=D, given=Daoguang, family=Zan and given-i=B, given=Bei, family=Chen and given-i=F, given=Fengji, family=Zhang and given-i=D, given=Dianjie, family=Lu and given-i=B, given=Bingchao, family=Wu and given-i=B, given=Bei, family=Guan and given-i=Y, given=Yongji, family=Wang and given-i=J, given=Jian-Guang, family=Lou},
	date = {2022-12-19},
	title = {Large language models meet NL2Code: a survey},
	url = {https://arxiv.org/abs/2212.09420},
	urldate = {2024-12-26},
}

@online{chen-2023,
	author = {given-i=B, given=Banghao, family=Chen and given-i=Z, given=Zhaofeng, family=Zhang and given-i=N, given=Nicolas, family=Langrené and given-i=S, given=Shengxin, family=Zhu},
	date = {2023-10-23},
	title = {Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review},
	url = {https://arxiv.org/abs/2310.14735v5},
	urldate = {2024-12-26},
}

@online{toth-2024,
	author = {given-i=R, given=Rebeka, family=Tóth and given-i=T, given=Tamas, family=Bisztray and given-i=L, given=László, family=Erdodi},
	date = {2024-04-21},
	title = {LLMs in Web Development: Evaluating LLM-Generated PHP Code Unveiling Vulnerabilities and Limitations},
	url = {https://arxiv.org/abs/2404.14459v2},
	urldate = {2025-01-05},
}
%----------- Ende: Einleitung --------------------------------------------------------------

@article{mohamad-2016,
	author = {Mohamad, Radziah and Yassin, Noraniah and Sandin, Easter},
	year = {2016},
	month = {12},
	pages = {7-11},
	title = {Comparative Evaluation of Automated Unit Testing Tool for PHP},
	volume = {2},
	journal = {International Journal of Software Engineering and Technology}
}

@inproceedings{anggrain-2016,
	author = {Anggrainingsih, Rini and Okta, Bara and Kuswara, Aprilla and Wahyuningsih, Daru and Rejekiningsih, Triana},
	year = {2016},
	month = {08},
	pages = {273-277},
	title = {Comparison of maintainability and flexibility on open source LMS},
	doi = {10.1109/ISEMANTIC.2016.7873850}
}

@online{da-silva-simoes-2024,
	author = {given-i=IR, given={Igor Regis}, family={Da Silva Simões} and given-i=E, given=Elaine, family=Venson},
	date = {2024-08-07},
	title = {Evaluating Source Code Quality with Large Language Models: a comparative study},
	url = {https://arxiv.org/abs/2408.07082},
	urldate = {2024-12-30},
}

%----------- Start: Konzeption --------------------------------------------------------------------
%% Qwen2.5-Coder
@online{qwen-2024,
	author = {given-i=Q, given=Qwen and given-i=A, given=An, family=Yang and given-i=B, given=Baosong, family=Yang and given-i=B, given=Beichen, family=Zhang and given-i=B, given=Binyuan, family=Hui and given-i=B, given=Bo, family=Zheng and given-i=B, given=Bowen, family=Yu and given-i=C, given=Chengyuan, family=Li and given-i=D, given=Dayiheng, family=Liu and given-i=F, given=Fei, family=Huang and given-i=H, given=Haoran, family=Wei and given-i=H, given=Huan, family=Lin and given-i=J, given=Jian, family=Yang and given-i=J, given=Jianhong, family=Tu and given-i=J, given=Jianwei, family=Zhang and given-i=J, given=Jianxin, family=Yang and given-i=J, given=Jiaxi, family=Yang and given-i=J, given=Jingren, family=Zhou and given-i=J, given=Junyang, family=Lin and given-i=K, given=Kai, family=Dang and given-i=K, given=Keming, family=Lu and given-i=K, given=Keqin, family=Bao and given-i=K, given=Kexin, family=Yang and given-i=L, given=Le, family=Yu and given-i=M, given=Mei, family=Li and given-i=M, given=Mingfeng, family=Xue and given-i=P, given=Pei, family=Zhang and given-i=Q, given=Qin, family=Zhu and given-i=R, given=Rui, family=Men and given-i=R, given=Runji, family=Lin and given-i=T, given=Tianhao, family=Li and given-i=T, given=Tianyi, family=Tang and given-i=T, given=Tingyu, family=Xia and given-i=X, given=Xingzhang, family=Ren and given-i=X, given=Xuancheng, family=Ren and given-i=Y, given=Yang, family=Fan and given-i=Y, given=Yang, family=Su and given-i=Y, given=Yichang, family=Zhang and given-i=Y, given=Yu, family=Wan and given-i=Y, given=Yuqiong, family=Liu and given-i=Z, given=Zeyu, family=Cui and given-i=Z, given=Zhenru, family=Zhang and given-i=Z, given=Zihan, family=Qiu},
	date = {2024-12-19},
	title = {QWen2.5 Technical Report},
	url = {https://arxiv.org/abs/2412.15115},
	urldate = {2025-01-09},
}
@online{hui-2024,
	author = {given-i=B, given=Binyuan, family=Hui and given-i=J, given=Jian, family=Yang and given-i=Z, given=Zeyu, family=Cui and given-i=J, given=Jiaxi, family=Yang and given-i=D, given=Dayiheng, family=Liu and given-i=L, given=Lei, family=Zhang and given-i=T, given=Tianyu, family=Liu and given-i=J, given=Jiajun, family=Zhang and given-i=B, given=Bowen, family=Yu and given-i=K, given=Keming, family=Lu and given-i=K, given=Kai, family=Dang and given-i=Y, given=Yang, family=Fan and given-i=Y, given=Yichang, family=Zhang and given-i=A, given=An, family=Yang and given-i=R, given=Rui, family=Men and given-i=F, given=Fei, family=Huang and given-i=B, given=Bo, family=Zheng and given-i=Y, given=Yibo, family=Miao and given-i=S, given=Shanghaoran, family=Quan and given-i=Y, given=Yunlong, family=Feng and given-i=X, given=Xingzhang, family=Ren and given-i=X, given=Xuancheng, family=Ren and given-i=J, given=Jingren, family=Zhou and given-i=J, given=Junyang, family=Lin},
	date = {2024-09-18},
	title = {QWen2.5-Coder Technical Report},
	url = {https://arxiv.org/abs/2409.12186},
	urldate = {2025-01-09},
}
%% DeepSeek-Coder-V2
@online{deepseek-ai-2024,
	author = {given-i=D, given=DeepSeek-Ai and given-i=Q, given=Qihao, family=Zhu and given-i=D, given=Daya, family=Guo and given-i=Z, given=Zhihong, family=Shao and given-i=D, given=Dejian, family=Yang and given-i=P, given=Peiyi, family=Wang and given-i=R, given=Runxin, family=Xu and given-i=Y, given=Y., family=Wu and given-i=Y, given=Yukun, family=Li and given-i=H, given=Huazuo, family=Gao and given-i=S, given=Shirong, family=Ma and given-i=W, given=Wangding, family=Zeng and given-i=X, given=Xiao, family=Bi and given-i=Z, given=Zihui, family=Gu and given-i=H, given=Hanwei, family=Xu and given-i=D, given=Damai, family=Dai and given-i=K, given=Kai, family=Dong and given-i=L, given=Liyue, family=Zhang and given-i=Y, given=Yishi, family=Piao and given-i=Z, given=Zhibin, family=Gou and given-i=Z, given=Zhenda, family=Xie and given-i=Z, given=Zhewen, family=Hao and given-i=B, given=Bingxuan, family=Wang and given-i=J, given=Junxiao, family=Song and given-i=D, given=Deli, family=Chen and given-i=X, given=Xin, family=Xie and given-i=K, given=Kang, family=Guan and given-i=Y, given=Yuxiang, family=You and given-i=A, given=Aixin, family=Liu and given-i=Q, given=Qiushi, family=Du and given-i=W, given=Wenjun, family=Gao and given-i=X, given=Xuan, family=Lu and given-i=Q, given=Qinyu, family=Chen and given-i=Y, given=Yaohui, family=Wang and given-i=C, given=Chengqi, family=Deng and given-i=J, given=Jiashi, family=Li and given-i=C, given=Chenggang, family=Zhao and given-i=C, given=Chong, family=Ruan and given-i=F, given=Fuli, family=Luo and given-i=W, given=Wenfeng, family=Liang},
	date = {2024-06-17},
	title = {DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence},
	url = {https://arxiv.org/abs/2406.11931},
	urldate = {2025-01-09},
}
@online{cui-2024,
	author = {given-i=Y, given=Yi, family=Cui},
	date = {2024-07-30},
	title = {WebApp1K: A Practical Code-Generation Benchmark for Web App Development},
	url = {https://arxiv.org/abs/2408.00019v1},
	urldate = {2025-01-09},
}
%% llama3.1-claude
@online{ollama_page_llama31_claude,
	title = {Modelcard Llama3.1-claude on Ollama},
	url = {https://ollama.com/incept5/llama3.1-claude},
	urldate = {2025-01-09},
}
@online{huggingface_page_llama31_claude,
	title = {Model Meta-Llama-3.1-8B-Claude on Hugging face},
	url = {https://huggingface.co/Undi95/Meta-Llama-3.1-8B-Claude},
	urldate = {2025-01-09},
}
@online{meta-llama-no-date,
	author = {given-i=M, given=Meta-Llama},
	title = {Llama 3.1 Modelcard},
	url = {https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md},
	urldate = {2025-01-09},
}
%% Mistral
@online{eberhardinger-2024,
	author = {given-i=M, given=Manuel, family=Eberhardinger and given-i=J, given=James, family=Goodman and given-i=A, given=Alexander, family=Dockhorn and given-i=D, given=Diego, family=Perez-Liebana and given-i=RD, given={Raluca D.}, family=Gaina and given-i=D, given=Duygu, family=Çakmak and given-i=S, given=Setareh, family=Maghsudi and given-i=S, given=Simon, family=Lucas},
	date = {2024-12-05},
	title = {From Code to Play: Benchmarking Program Search for Games Using Large Language Models},
	url = {https://arxiv.org/abs/2412.04057v1},
	urldate = {2025-01-09},
}
@online{quan-2024,
	author = {given-i=X, given=Xin, family=Quan and given-i=M, given=Marco, family=Valentino and given-i=LA, given={Louise A.}, family=Dennis and given-i=A, given=André, family=Freitas},
	date = {2024-05-02},
	title = {Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving},
	url = {https://arxiv.org/abs/2405.01379v4},
	urldate = {2025-01-09},
}
%% ChatGPT 
@online{ahmed-2025,
	author = {given-i=A, given=Ammar, family=Ahmed and given-i=M, given=Margarida, family=Fresco and given-i=F, given=Fredrik, family=Forsberg and given-i=H, given=Hallvard, family=Grotli},
	date = {2025-01-07},
	title = {From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study},
	url = {https://arxiv.org/abs/2501.03572v1},
	urldate = {2025-01-10},
}
@report{openai_model_overview,
	title = {Models},
	url = {https://platform.openai.com/docs/models},
	urldate = {2025-01-10},
}
%% Gemini
@online{siam-2024,
	author = {given-i=MK, given={Md Kamrul}, family=Siam and given-i=H, given=Huanying, family=Gu and given-i=JQ, given={Jerry Q.}, family=Cheng},
	date = {2024-11-14},
	title = {Programming with AI: Evaluating ChatGPT, Gemini, AlphaCode, and GitHub Copilot for Programmers},
	url = {https://arxiv.org/abs/2411.09224v1},
	urldate = {2025-01-10},
}
@online{elgedawy-2024,
	author = {given-i=R, given=Ran, family=Elgedawy and given-i=J, given=John, family=Sadik and given-i=S, given=Senjuti, family=Dutta and given-i=A, given=Anuj, family=Gautam and given-i=K, given=Konstantinos, family=Georgiou and given-i=F, given=Farzin, family=Gholamrezae and given-i=F, given=Fujiao, family=Ji and given-i=K, given=Kyungchan, family=Lim and given-i=Q, given=Qian, family=Liu and given-i=S, given=Scott, family=Ruoti},
	date = {2024-02-01},
	title = {Ocassionally Secure: A Comparative Analysis of Code Generation Assistants},
	url = {https://arxiv.org/abs/2402.00689v1},
	urldate = {2025-01-10},
}
@online{google_gemini_model_overview,
	title = {Gemini-Modelle},
	url = {https://ai.google.dev/gemini-api/docs/models/gemini?hl=de},
	urldate = {2025-01-10},
}


%----------- Ende: Konzeption ---------------------------------------------------------------------
%----------- Start: Stand der Technik -------------------------------------------------------------
@online{li-2024,
	author = {given-i=J, given=Jia, family=Li and given-i=Y, given=Yuqi, family=Zhu and given-i=Y, given=Yongmin, family=Li and given-i=G, given=Ge, family=Li and given-i=Z, given=Zhi, family=Jin},
	date = {2024-10-04},
	title = {Showing LLM-Generated Code Selectively Based on Confidence of LLMs},
	url = {https://arxiv.org/abs/2410.03234},
	urldate = {2024-12-20},
}

@online{jiang-2024,
	author = {given-i=J, given=Juyong, family=Jiang and given-i=F, given=Fan, family=Wang and given-i=J, given=Jiasi, family=Shen and given-i=S, given=Sungju, family=Kim and given-i=S, given=Sunghun, family=Kim},
	date = {2024-06-01},
	title = {A Survey on Large Language Models for Code Generation},
	url = {https://arxiv.org/abs/2406.00515},
	urldate = {2024-11-07},
}

@article{velasquez-henao-2023,
	author = {given-i=JD, given={Juan David}, family=Velásquez-Henao and given-i=CJ, given={Carlos Jaime}, family=Franco-Cardona and given-i=L, given=Lorena, family=Cadavid-Higuita},
	date = {2023-11-03},
	doi = {10.15446/dyna.v90n230.111700},
	journaltitle = {DYNA},
	number = {230},
	pages = {9--17},
	title = {Prompt Engineering: a methodology for optimizing interactions with AI-Language Models in the field of engineering},
	url = {https://doi.org/10.15446/dyna.v90n230.111700},
	volume = {90},
}

@online{mishra-2024,
	author = {given-i=M, given=Mayank, family=Mishra and given-i=M, given=Matt, family=Stallone and given-i=G, given=Gaoyuan, family=Zhang and given-i=Y, given=Yikang, family=Shen and given-i=A, given=Aditya, family=Prasad and given-i=AM, given={Adriana Meza}, family=Soria and given-i=M, given=Michele, family=Merler and given-i=P, given=Parameswaran, family=Selvam and given-i=S, given=Saptha, family=Surendran and given-i=S, given=Shivdeep, family=Singh and given-i=M, given=Manish, family=Sethi and given-i=X, given=Xuan-Hong, family=Dang and given-i=P, given=Pengyuan, family=Li and given-i=K, given=Kun-Lung, family=Wu and given-i=S, given=Syed, family=Zawad and given-i=A, given=Andrew, family=Coleman and given-i=M, given=Matthew, family=White and given-i=M, given=Mark, family=Lewis and given-i=R, given=Raju, family=Pavuluri and given-i=Y, given=Yan, family=Koyfman and given-i=B, given=Boris, family=Lublinsky and given-i=DB, given={De Bayser}, family=Maximilien and given-i=I, given=Ibrahim, family=Abdelaziz and given-i=K, given=Kinjal, family=Basu and given-i=M, given=Mayank, family=Agarwal and given-i=Y, given=Yi, family=Zhou and given-i=C, given=Chris, family=Johnson and given-i=A, given=Aanchal, family=Goyal and given-i=H, given=Hima, family=Patel and given-i=Y, given=Yousaf, family=Shah and given-i=P, given=Petros, family=Zerfos and given-i=H, given=Heiko, family=Ludwig and given-i=A, given=Asim, family=Munawar and given-i=M, given=Maxwell, family=Crouse and given-i=P, given=Pavan, family=Kapanipathi and given-i=S, given=Shweta, family=Salaria and given-i=B, given=Bob, family=Calio and given-i=S, given=Sophia, family=Wen and given-i=S, given=Seetharami, family=Seelam and given-i=B, given=Brian, family=Belgodere and given-i=C, given=Carlos, family=Fonseca and given-i=A, given=Amith, family=Singhee and given-i=N, given=Nirmit, family=Desai and given-i=DD, given={David D.}, family=Cox and given-i=R, given=Ruchir, family=Puri and given-i=R, given=Rameswar, family=Panda},
	date = {2024-05-07},
	title = {Granite Code Models: A Family of Open Foundation Models for Code Intelligence},
	url = {https://arxiv.org/abs/2405.04324},
	urldate = {2024-11-08},
}

@online{lozhkov-2024,
	author = {given-i=A, given=Anton, family=Lozhkov and given-i=R, given=Raymond, family=Li and given-i=LB, given={Loubna Ben}, family=Allal and given-i=F, given=Federico, family=Cassano and given-i=J, given=Joel, family=Lamy-Poirier and given-i=N, given=Nouamane, family=Tazi and given-i=A, given=Ao, family=Tang and given-i=D, given=Dmytro, family=Pykhtar and given-i=J, given=Jiawei, family=Liu and given-i=Y, given=Yuxiang, family=Wei and given-i=T, given=Tianyang, family=Liu and given-i=M, given=Max, family=Tian and given-i=D, given=Denis, family=Kocetkov and given-i=A, given=Arthur, family=Zucker and given-i=Y, given=Younes, family=Belkada and given-i=Z, given=Zijian, family=Wang and given-i=Q, given=Qian, family=Liu and given-i=D, given=Dmitry, family=Abulkhanov and given-i=I, given=Indraneil, family=Paul and given-i=Z, given=Zhuang, family=Li and given-i=W, given=Wen-Ding, family=Li and given-i=M, given=Megan, family=Risdal and given-i=J, given=Jia, family=Li and given-i=J, given=Jian, family=Zhu and given-i=TY, given={Terry Yue}, family=Zhuo and given-i=E, given=Evgenii, family=Zheltonozhskii and given-i=NOO, given={Nii Osae Osae}, family=Dade and given-i=W, given=Wenhao, family=Yu and given-i=L, given=Lucas, family=Krauß and given-i=N, given=Naman, family=Jain and given-i=Y, given=Yixuan, family=Su and given-i=X, given=Xuanli, family=He and given-i=M, given=Manan, family=Dey and given-i=E, given=Edoardo, family=Abati and given-i=Y, given=Yekun, family=Chai and given-i=N, given=Niklas, family=Muennighoff and given-i=X, given=Xiangru, family=Tang and given-i=M, given=Muhtasham, family=Oblokulov and given-i=C, given=Christopher, family=Akiki and given-i=M, given=Marc, family=Marone and given-i=C, given=Chenghao, family=Mou and given-i=M, given=Mayank, family=Mishra and given-i=A, given=Alex, family=Gu and given-i=B, given=Binyuan, family=Hui and given-i=T, given=Tri, family=Dao and given-i=A, given=Armel, family=Zebaze and given-i=O, given=Olivier, family=Dehaene and given-i=N, given=Nicolas, family=Patry and given-i=C, given=Canwen, family=Xu and given-i=J, given=Julian, family=McAuley and given-i=H, given=Han, family=Hu and given-i=T, given=Torsten, family=Scholak and given-i=S, given=Sebastien, family=Paquet and given-i=J, given=Jennifer, family=Robinson and given-i=CJ, given={Carolyn Jane}, family=Anderson and given-i=N, given=Nicolas, family=Chapados and given-i=M, given=Mostofa, family=Patwary and given-i=N, given=Nima, family=Tajbakhsh and given-i=Y, given=Yacine, family=Jernite and given-i=CM, given={Carlos Muñoz}, family=Ferrandis and given-i=L, given=Lingming, family=Zhang and given-i=S, given=Sean, family=Hughes and given-i=T, given=Thomas, family=Wolf and given-i=A, given=Arjun, family=Guha and given-i=VW, given={Von Werra}, family=Leandro and given-i=DV, given={De Vries}, family=Harm},
	date = {2024-02-29},
	title = {StarCoder 2 and The Stack v2: The Next Generation},
	url = {https://arxiv.org/abs/2402.19173},
	urldate = {2024-11-08},
}

@article{nataraj-2024,
	author = {"given-i=SC1DD2T3,S", "given={Sasikala C 1 Dr.M.Kalpana Devi 2,Tholhappiyan T 3, Sasikala}", family=Nataraj},
	date = {2024-08-17},
	title = {REVOLUTIONIZING WEB DEVELOPMENT WITH AN INTELLIGENT CHATBOT: a NOVEL APPROACH UTILIZING OPENAI'S GPT-3 AND ADVANCED NLP STRATEGIES},
	url = {http://machineintelligenceresearchs.com/index.php/mir/article/view/90},
	urldate = {2024-11-08},
	
	journaltitle = {Machine Intennigence Research},
	number = {1},
	pages = {1098--1109},
	volume = {18},
}

%----------- Ende: Stand der Technik --------------------------------------------------------------

@online{noauthor_developers_2024,
	title = {Developers want more, more, more: the 2024 results from Stack Overflow’s Annual Developer Survey},
	author = {Yepis, Erin},
	url = {https://stackoverflow.blog/2024/07/24/developers-want-more-more-more-the-2024-results-from-stack-overflow-s-annual-developer-survey/},
	shorttitle = {Developers want more, more, more},
	urldate = {2024-08-09},
	date = {2024-07-24},
	langid = {english},
}

@report{definition_ki2019,
	author = {Ala-Pietilä, Pekka and Bauer, Wilhelm and Bergmann, Urs and Bielikova, Maria},
	date = {2019-03-05},
	title = {Eine Definition der KI: Wichtigste Fähigkeiten und Wissenschaftsgebiete},
	url = {https://elektro.at/wp-content/uploads/2019/10/EU_Definition-KI.pdf},
	urldate = {2024-09-10},
}

@article{yuen_universal_2021,
	title = {Universal activation function for machine learning},
	volume = {11},
	issn = {2045-2322},
	url = {https://doi.org/10.1038/s41598-021-96723-8},
	doi = {10.1038/s41598-021-96723-8},
	pages = {18757},
	number = {1},
	abstract = {This article proposes a universal activation function ({UAF}) that achieves near optimal performance in quantification, classification, and reinforcement learning ({RL}) problems. For any given problem, the gradient descent algorithms are able to evolve the {UAF} to a suitable activation function by tuning the {UAF}’s parameters. For the {CIFAR}-10 classification using the {VGG}-8 neural network, the {UAF} converges to the Mish like activation function, which has near optimal performance \$\$F\_\{1\}=0.902{\textbackslash}pm 0.004\$\$when compared to other activation functions. In the graph convolutional neural network on the {CORA} dataset, the {UAF} evolves to the identity function and obtains \$\$F\_1=0.835{\textbackslash}pm 0.008\$\$. For the quantification of simulated 9-gas mixtures in 30 {dB} signal-to-noise ratio ({SNR}) environments, the {UAF} converges to the identity function, which has near optimal root mean square error of \$\$0.489{\textbackslash}pm 0.003{\textasciitilde}{\textbackslash}mu \{{\textbackslash}mathrm\{M\}\}\$\$. In the {ZINC} molecular solubility quantification using graph neural networks, the {UAF} morphs to a {LeakyReLU}/Sigmoid hybrid and achieves {RMSE}=\$\$0.47{\textbackslash}pm 0.04\$\$. For the {BipedalWalker}-v2 {RL} dataset, the {UAF} achieves the 250 reward in \$\$\{961{\textbackslash}pm 193\}\$\$epochs with a brand new activation function, which gives the fastest convergence rate among the activation functions.},
	journaltitle = {Scientific Reports},
	shortjournal = {Scientific Reports},
	author = {Yuen, Brosnan and Hoang, Minh Tu and Dong, Xiaodai and Lu, Tao},
	date = {2021-09-21},
}

@online{brownlee-2021,
	author = {given-i=JB, given=Jason, family=Brownlee},
	date = {2021-01-22},
	title = {How to Choose an Activation Function for Deep Learning},
	url = {https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/},
	urldate = {2024-09-19},
}

@report{sharma-2020,
	author = {given=Siddharth, family=Sharma and given=Simone, family=Sharma and given=Anidhya, family=Athaiya and {Dept. of Computer Science and Engineering, Global Institute of Technology, Jaipur}},
	date = {2020-04},
	number = {Issue 12},
	pages = {310--316},
	title = {{A}ctivation {F}unctions in {N}eural {N}etworks},
	url = {https://www.ijeast.com/papers/310-316,Tesma412,IJEAST.pdf},
	urldate = {2024-09-19},
	volume = {Vol. 4},
}

@online{cs231n_2024,
	title = {CS231n Convolutional Neural Networks for Visual Recognition},
	url = {https://cs231n.github.io/neural-networks-1/},
	urldate = {2024-09-20},
}

@article{rallabandi-2023,
	author = {given-i=S, given=Srikari, family=Rallabandi},
	date = {2023-03-27},
	title = {Activation functions: ReLU vs. Leaky ReLU - Srikari Rallabandi - Medium},
	url = {https://medium.com/@sreeku.ralla/activation-functions-relu-vs-leaky-relu-b8272dc0b1be},
}

@online{bhargav-2023,
	author = {given-i=NB, given=Nikhil, family=Bhargav},
	date = {2023-11-27},
	title = {ReLU vs. LeakyReLU vs. PReLU | Baeldung on Computer Science},
	url = {https://www.baeldung.com/cs/relu-vs-leakyrelu-vs-prelu},
	urldate = {2024-09-20},
}

@misc{goodfellow_maxout_2013,
	title = {Maxout Networks},
	url = {http://arxiv.org/abs/1302.4389},
	doi = {10.48550/arXiv.1302.4389},
	abstract = {We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: {MNIST}, {CIFAR}-10, {CIFAR}-100, and {SVHN}.},
	number = {{arXiv}:1302.4389},
	publisher = {{arXiv}},
	author = {Goodfellow, Ian J. and Warde-Farley, David and Mirza, Mehdi and Courville, Aaron and Bengio, Yoshua},
	urldate = {2024-09-20},
	date = {2013-09-20},
	eprinttype = {arxiv},
	eprint = {1302.4389 [cs, stat]},
	note = {version: 4},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\w.pahl\\Zotero\\storage\\BLIVUG35\\Goodfellow et al. - 2013 - Maxout Networks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\w.pahl\\Zotero\\storage\\IXQ9W9WD\\1302.html:text/html},
}

@online{duden_unknown-author,
	title = {Der Umfang des deutschen Wortschatzes},
	date = {2020},
	url = {https://www.duden.de/sprachwissen/sprachratgeber/Zum-Umfang-des-deutschen-Wortschatzes},
	urldate = {2024-09-23},
}

@online{vaswani-2017,
	author = {given-i=A, given=Ashish, family=Vaswani and given-i=N, given=Noam, family=Shazeer and given-i=N, given=Niki, family=Parmar and given-i=J, given=Jakob, family=Uszkoreit and given-i=L, given=Llion, family=Jones and given-i=AN, given={Aidan N.}, family=Gomez and given-i=L, given=Lukasz, family=Kaiser and given-i=I, given=Illia, family=Polosukhin},
	date = {2017-06-12},
	title = {Attention is all you need},
	url = {https://arxiv.org/abs/1706.03762},
	urldate = {2024-09-23},
}

@article{goldberg-2016,
	author = {given-i=Y, given=Yoav, family=Goldberg},
	date = {2016-11-20},
	doi = {10.1613/jair.4992},
	journaltitle = {Journal of Artificial Intelligence Research},
	pages = {345--420},
	title = {A Primer on Neural Network Models for Natural Language Processing},
	url = {https://jair.org/index.php/jair/article/view/11030},
	volume = {57},
}

@image{pahl-2024,
	author = {given=Johanna, family=Pahl},
	date = {2024-09-26},
	title = {Zeichnung einer biologische Zelle},
}

@inproceedings{handschuh-2024,
	author = {given-i=SH, given=Siegfried, family=Handschuh},
	date = {2024-05-06},
	title = {Grosse Sprachmodelle},
	url = {https://bop.unibe.ch/iw/article/view/11053/13941},
	urldate = {2024-09-28},
	eventtitle = {Travaux du/Arbeiten aus dem Master of Advanced Studies in Archival Band 8 Nr. 1},
	publisher = {Gesellschaft für Informatik e.V.},
	langid = {german},
}

@online{du-2024,
	author = {given-i=Z, given=Zhuoyun, family=Du and given-i=C, given=Chen, family=Qian and given-i=W, given=Wei, family=Liu and given-i=Z, given=Zihao, family=Xie and given-i=Y, given=Yifei, family=Wang and given-i=Y, given=Yufan, family=Dang and given-i=W, given=Weize, family=Chen and given-i=C, given=Cheng, family=Yang},
	date = {2024-06-13},
	title = {Multi-Agent Software Development through Cross-Team Collaboration},
	url = {https://arxiv.org/abs/2406.08979},
	urldate = {2024-10-04},
}

% -- Prompt engineering
@online{zhou-2022,
	author = {given-i=Y, given=Yongchao, family=Zhou and given-i=AI, given={Andrei Ioan}, family=Muresanu and given-i=Z, given=Ziwen, family=Han and given-i=K, given=Keiran, family=Paster and given-i=S, given=Silviu, family=Pitis and given-i=H, given=Harris, family=Chan and given-i=J, given=Jimmy, family=Ba},
	date = {2022-11-03},
	title = {Large language models are Human-Level prompt engineers},
	url = {https://arxiv.org/abs/2211.01910},
	urldate = {2024-10-12},
}

@online{amatriain-2024,
	author = {given-i=X, given=Xavier, family=Amatriain},
	date = {2024-01-24},
	title = {Prompt Design and Engineering: Introduction and Advanced Methods},
	url = {https://arxiv.org/abs/2401.14423v3},
	urldate = {2024-10-12},
}

@online{wei-2021,
	author = {given-i=J, given=Jason, family=Wei and given-i=M, given=Maarten, family=Bosma and given-i=VY, given={Vincent Y.}, family=Zhao and given-i=K, given=Kelvin, family=Guu and given-i=AW, given={Adams Wei}, family=Yu and given-i=B, given=Brian, family=Lester and given-i=N, given=Nan, family=Du and given-i=AM, given={Andrew M.}, family=Dai and given-i=Q, given=Quoc, family=Le, suffix=V},
	date = {2021-09-03},
	title = {Finetuned language models are Zero-Shot learners},
	url = {https://arxiv.org/abs/2109.01652},
	urldate = {2024-10-12},
}

@online{brown-2020,
	author = {given-i=TB, given={Tom B.}, family=Brown and given-i=B, given=Benjamin, family=Mann and given-i=N, given=Nick, family=Ryder and given-i=M, given=Melanie, family=Subbiah and given-i=J, given=Jared, family=Kaplan and given-i=P, given=Prafulla, family=Dhariwal and given-i=A, given=Arvind, family=Neelakantan and given-i=P, given=Pranav, family=Shyam and given-i=G, given=Girish, family=Sastry and given-i=A, given=Amanda, family=Askell and given-i=S, given=Sandhini, family=Agarwal and given-i=A, given=Ariel, family=Herbert-Voss and given-i=G, given=Gretchen, family=Krueger and given-i=T, given=Tom, family=Henighan and given-i=R, given=Rewon, family=Child and given-i=A, given=Aditya, family=Ramesh and given-i=DM, given={Daniel M.}, family=Ziegler and given-i=J, given=Jeffrey, family=Wu and given-i=C, given=Clemens, family=Winter and given-i=C, given=Christopher, family=Hesse and given-i=M, given=Mark, family=Chen and given-i=E, given=Eric, family=Sigler and given-i=M, given=Mateusz, family=Litwin and given-i=S, given=Scott, family=Gray and given-i=B, given=Benjamin, family=Chess and given-i=J, given=Jack, family=Clark and given-i=C, given=Christopher, family=Berner and given-i=S, given=Sam, family=McCandlish and given-i=A, given=Alec, family=Radford and given-i=I, given=Ilya, family=Sutskever and given-i=D, given=Dario, family=Amodei},
	date = {2020-05-28},
	title = {Language Models are Few-Shot Learners},
	url = {https://arxiv.org/abs/2005.14165},
	urldate = {2024-10-12},
}

@online{min-2022,
	author = {given-i=S, given=Sewon, family=Min and given-i=X, given=Xinxi, family=Lyu and given-i=A, given=Ari, family=Holtzman and given-i=M, given=Mikel, family=Artetxe and given-i=M, given=Mike, family=Lewis and given-i=H, given=Hannaneh, family=Hajishirzi and given-i=L, given=Luke, family=Zettlemoyer},
	date = {2022-02-25},
	title = {Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
	url = {https://arxiv.org/abs/2202.12837},
	urldate = {2024-10-12},
}

@online{wei-2022,
	author = {given-i=J, given=Jason, family=Wei and given-i=X, given=Xuezhi, family=Wang and given-i=D, given=Dale, family=Schuurmans and given-i=M, given=Maarten, family=Bosma and given-i=B, given=Brian, family=Ichter and given-i=F, given=Fei, family=Xia and given-i=E, given=Ed, family=Chi and given-i=Q, given=Quoc, family=Le and given-i=D, given=Denny, family=Zhou},
	date = {2022-01-28},
	title = {Chain-of-Thought prompting elicits reasoning in large language models},
	url = {https://arxiv.org/abs/2201.11903},
	urldate = {2024-10-12},
}

@online{zhang-2023,
	author = {given-i=Y, given=Yifan, family=Zhang and given-i=Y, given=Yang, family=Yuan and given-i=AC, given={Andrew Chi-Chih}, family=Yao},
	date = {2023-11-20},
	title = {Meta Prompting for AI Systems},
	url = {https://arxiv.org/abs/2311.11482},
	urldate = {2024-10-12},
}

@online{long-2023,
	author = {given-i=J, given=Jieyi, family=Long},
	date = {2023-05-15},
	title = {Large language model guided Tree-of-Thought},
	url = {https://arxiv.org/abs/2305.08291},
	urldate = {2024-10-14},
}

@online{yao-2023,
	author = {given-i=S, given=Shunyu, family=Yao and given-i=D, given=Dian, family=Yu and given-i=J, given=Jeffrey, family=Zhao and given-i=I, given=Izhak, family=Shafran and given-i=TL, given={Thomas L.}, family=Griffiths and given-i=Y, given=Yuan, family=Cao and given-i=K, given=Karthik, family=Narasimhan},
	date = {2023-05-17},
	title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
	url = {https://arxiv.org/abs/2305.10601},
	urldate = {2024-10-14},
}

% ----------

@book{banholzer-2020,
	author = {given={Volker M.}, family=Banholzer},
	date = {2020},
	publisher = {Technische Hochschule Nürnberg Georg-Simon-Ohm},
	title = {Künstliche Intelligenz als Treiber der Veränderung in der Unternehmenskommunikation 4.0?},
	url = {https://www.th-nuernberg.de/fileadmin/fakultaeten/amp/amp_docs/K%C3%BCnstliche_Intelligenz_und_die_Rolle_n__von_Unternehmenskommunikation_Banholzer_IKOM_WP_1_2020__fin-1.pdf},
	volume = {1/2020},
}

@report{oswald-2022,
	date = {2022},
	edition = {2. Auflage},
	editor = {given=Gerhard, family=Oswald and given=Thomas, family=Saueressig and {Helmut Krcmar}},
	publisher = {Springer},
	title = {Digitale Transformation: Fallbeispiele und Branchenanalysen},
	url = {https://library.oapen.org/bitstream/handle/20.500.12657/57358/978-3-658-37571-3.pdf?sequence=1&utm_source=textcortex&utm_medium=zenochat#page=70},
	urldate = {2024-10-19},
}


% Disscussion
@inproceedings{hartenstein_2024,
	title = {{KI}-gestützte Modernisierung von Altanwendungen: Anwendungsfelder von {LLMs} im Software Reengineering},
	url = {https://dl.gi.de/handle/20.500.12116/44181},
	shorttitle = {{KI}-gestützte Modernisierung von Altanwendungen},
	abstract = {Die Integration von Large Language Models, kurz {LLMs}, in den Modernisierungsprozess von Altanwendungen bietet nicht nur eine Vielzahl technologischer Möglichkeiten, sondern dient auch als starke Motivation für Unternehmen, ihre bestehenden Systeme zu verbessern. {LLMs} repräsentieren einen bedeutsamen Fortschritt in der künstlichen Intelligenz ({KI}), veraltete Anwendungen können mit, aber auch durch {LLMs} aufgewertet werden. Diese Ausarbeitung adressiert die folgenden Fragen zur Implementierung von {LLMs} im Modernisierungsprozess: {FF}1 Wie können {LLMs} die Modernisierung von Altan wendungen im Anforderungsmanagement unter stützen? {FF}2 Inwiefern ermöglichen {LLMs} effiziente Software Reengineering Prozesse?},
	eventtitle = {Softwaretechnik-Trends Band 44, Heft 2},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Hartenstein, Sandro and Schmietendorf, Andreas},
	urldate = {2024-08-15},
	date = {2024},
	langid = {german},
}

@article{chiriatti-2024,
	author = {given-i=M, given=Massimo, family=Chiriatti and given-i=M, given=Marianna, family=Ganapini and given-i=E, given=Enrico, family=Panai and given-i=M, given=Mario, family=Ubiali and given-i=G, given=Giuseppe, family=Riva},
	date = {2024-10-22},
	doi = {10.1038/s41562-024-01995-5},
	journaltitle = {Nature Human Behaviour},
	number = {10},
	pages = {1829--1830},
	title = {The case for human–AI interaction as system 0 thinking},
	url = {https://www.nature.com/articles/s41562-024-01995-5},
	volume = {8},
}


% -- Start Evaluierung ---
@online{chen-2021,
	author = {given-i=M, given=Mark, family=Chen and given-i=J, given=Jerry, family=Tworek and given-i=H, given=Heewoo, family=Jun and given-i=Q, given=Qiming, family=Yuan and given-i=HP, given={Henrique Ponde}, family={De Oliveira Pinto} and given-i=J, given=Jared, family=Kaplan and given-i=H, given=Harri, family=Edwards and given-i=Y, given=Yuri, family=Burda and given-i=N, given=Nicholas, family=Joseph and given-i=G, given=Greg, family=Brockman and given-i=A, given=Alex, family=Ray and given-i=R, given=Raul, family=Puri and given-i=G, given=Gretchen, family=Krueger and given-i=M, given=Michael, family=Petrov and given-i=H, given=Heidy, family=Khlaaf and given-i=G, given=Girish, family=Sastry and given-i=P, given=Pamela, family=Mishkin and given-i=B, given=Brooke, family=Chan and given-i=S, given=Scott, family=Gray and given-i=N, given=Nick, family=Ryder and given-i=M, given=Mikhail, family=Pavlov and given-i=A, given=Alethea, family=Power and given-i=L, given=Lukasz, family=Kaiser and given-i=M, given=Mohammad, family=Bavarian and given-i=C, given=Clemens, family=Winter and given-i=P, given=Philippe, family=Tillet and given-i=FP, given={Felipe Petroski}, family=Such and given-i=D, given=Dave, family=Cummings and given-i=M, given=Matthias, family=Plappert and given-i=F, given=Fotios, family=Chantzis and given-i=E, given=Elizabeth, family=Barnes and given-i=A, given=Ariel, family=Herbert-Voss and given-i=WH, given={William Hebgen}, family=Guss and given-i=A, given=Alex, family=Nichol and given-i=A, given=Alex, family=Paino and given-i=N, given=Nikolas, family=Tezak and given-i=J, given=Jie, family=Tang and given-i=I, given=Igor, family=Babuschkin and given-i=S, given=Suchir, family=Balaji and given-i=S, given=Shantanu, family=Jain and given-i=W, given=William, family=Saunders and given-i=C, given=Christopher, family=Hesse and given-i=AN, given={Andrew N.}, family=Carr and given-i=J, given=Jan, family=Leike and given-i=J, given=Josh, family=Achiam and given-i=V, given=Vedant, family=Misra and given-i=E, given=Evan, family=Morikawa and given-i=A, given=Alec, family=Radford and given-i=M, given=Matthew, family=Knight and given-i=M, given=Miles, family=Brundage and given-i=M, given=Mira, family=Murati and given-i=K, given=Katie, family=Mayer and given-i=P, given=Peter, family=Welinder and given-i=B, given=Bob, family=McGrew and given-i=D, given=Dario, family=Amodei and given-i=S, given=Sam, family=McCandlish and given-i=I, given=Ilya, family=Sutskever and given-i=W, given=Wojciech, family=Zaremba},
	date = {2021-07-07},
	title = {Evaluating Large Language Models Trained on Code},
	url = {https://arxiv.org/abs/2107.03374},
	urldate = {2024-10-28},
}

@online{peng-2024,
	author = {given-i=Q, given=Qiwei, family=Peng and given-i=Y, given=Yekun, family=Chai and given-i=X, given=Xuhong, family=Li},
	date = {2024-02-26},
	title = {HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual Natural Language Generalization},
	url = {https://arxiv.org/abs/2402.16694},
	urldate = {2024-11-15},
}

@online{hugging-face-2025,
	title = {GGUF},
	url = {https://huggingface.co/docs/hub/en/gguf},
	urldate = {2025-01-23},
}

@online{zhang-2024,
	author = {given-i=S, given=Shudan, family=Zhang and given-i=H, given=Hanlin, family=Zhao and given-i=X, given=Xiao, family=Liu and given-i=Q, given=Qinkai, family=Zheng and given-i=Z, given=Zehan, family=Qi and given-i=X, given=Xiaotao, family=Gu and given-i=X, given=Xiaohan, family=Zhang and given-i=Y, given=Yuxiao, family=Dong and given-i=J, given=Jie, family=Tang},
	date = {2024-05-07},
	title = {NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts},
	url = {https://arxiv.org/abs/2405.04520},
	urldate = {2025-02-21},
}
% -- Ende Evaluierung ---

% -- Start Discussion ---
@online{albrecht-2023,
	author = {given-i=SA, given=Steffen, family=Albrecht and {Karlsruher Institut für Technologie (KIT)}},
	date = {2023-04-25},
	title = {Was ChatGPT für Bildung und Wissenschaft bedeutet},
	url = {https://www.helmholtz.de/newsroom/artikel/was-chatgpt-fuer-bildung-und-wissenschaft-bedeutet/},
	urldate = {2025-02-22},
}

@article{focus-online-2025,
	author = {{FOCUS online}},
	date = {2025-02-21},
	publisher = {FOCUS online},
	title = {Macht KI uns dümmer? Forscher untersuchen Auswirkungen von Chatbots auf Lern- und Denkfähigkeiten},
	url = {https://www.focus.de/wissen/macht-ki-uns-duemmer-forscher-untersuchen-auswirkungen-von-chatbots-auf-lern-und-denkfaehigkeiten_id_260737569.html},
}
% -- Ende Discussion ---